{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1a130f14e7f043358916cc067cd297a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28aa98261b6947d9a97858dcff50ff4d","IPY_MODEL_7d2a2d2f64034c21b1d3c7ecc7ba06f7","IPY_MODEL_4bed7ad51aab48d1b9803923ba1aa042"],"layout":"IPY_MODEL_380394d7c571473dbe9d258612987f5d"}},"28aa98261b6947d9a97858dcff50ff4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8064793281bc4eff8d506682f2b1f80b","placeholder":"​","style":"IPY_MODEL_4dda68733df8475bbf4294976181c799","value":"Downloading (…)okenizer_config.json: 100%"}},"7d2a2d2f64034c21b1d3c7ecc7ba06f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a58a16faf4e44ee28c783217b723d871","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e69c52fe88244839ce1d70ededd401a","value":28}},"4bed7ad51aab48d1b9803923ba1aa042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db7e7b07eb4c46cea94e01574bdd5e08","placeholder":"​","style":"IPY_MODEL_81ac5e57b0ba429fa741b7b320664927","value":" 28.0/28.0 [00:00&lt;00:00, 1.40kB/s]"}},"380394d7c571473dbe9d258612987f5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8064793281bc4eff8d506682f2b1f80b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dda68733df8475bbf4294976181c799":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a58a16faf4e44ee28c783217b723d871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e69c52fe88244839ce1d70ededd401a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db7e7b07eb4c46cea94e01574bdd5e08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ac5e57b0ba429fa741b7b320664927":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32d468f9221e4514b133f493a1dc030f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b4e8c740e214363b26b0509762ff130","IPY_MODEL_17078612a6e14a93883325f96feabe55","IPY_MODEL_0629816b65b74c4f8cecf213b2e77c3b"],"layout":"IPY_MODEL_dc677cf184f547ea92f6297d949bd82a"}},"8b4e8c740e214363b26b0509762ff130":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32be718e944942fe839c3264f1e8ed38","placeholder":"​","style":"IPY_MODEL_d6f62776211f49dfa32c6842729daf7b","value":"Downloading (…)lve/main/config.json: 100%"}},"17078612a6e14a93883325f96feabe55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a779eb728cb4a6a8e989ec8c6d577f0","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1c96ea47a8c458b9f980373a0b3df98","value":570}},"0629816b65b74c4f8cecf213b2e77c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b14ea970f514a9bbb6838faf69c81ab","placeholder":"​","style":"IPY_MODEL_5e3d9bdb866b482ba1dd6636985e62de","value":" 570/570 [00:00&lt;00:00, 27.9kB/s]"}},"dc677cf184f547ea92f6297d949bd82a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32be718e944942fe839c3264f1e8ed38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f62776211f49dfa32c6842729daf7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a779eb728cb4a6a8e989ec8c6d577f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c96ea47a8c458b9f980373a0b3df98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b14ea970f514a9bbb6838faf69c81ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e3d9bdb866b482ba1dd6636985e62de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33f923d8da7b48569d1a4664cdd61df8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0c89b8f705243e980a3c9525ec420eb","IPY_MODEL_429f32080efb47d1acbf6f9fc2a1141c","IPY_MODEL_34956745f3824600968f181aca0e08d9"],"layout":"IPY_MODEL_d6ffa4759e714bc4a5aa918119a8e498"}},"e0c89b8f705243e980a3c9525ec420eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_166bc6e9565a478e8ac7dd94f660e439","placeholder":"​","style":"IPY_MODEL_e1a87ab4fdd04bcb8303acb921d38d9c","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"429f32080efb47d1acbf6f9fc2a1141c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4c433b7cb134e438dbf3f2f4d97dbcb","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac714bc71d4249509387746467cc1ba8","value":231508}},"34956745f3824600968f181aca0e08d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49cd6e4478fa4ac7bbf8855d28d4cd67","placeholder":"​","style":"IPY_MODEL_303c1610be9e469d9680de67dcd32ea2","value":" 232k/232k [00:00&lt;00:00, 3.56MB/s]"}},"d6ffa4759e714bc4a5aa918119a8e498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"166bc6e9565a478e8ac7dd94f660e439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1a87ab4fdd04bcb8303acb921d38d9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4c433b7cb134e438dbf3f2f4d97dbcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac714bc71d4249509387746467cc1ba8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49cd6e4478fa4ac7bbf8855d28d4cd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"303c1610be9e469d9680de67dcd32ea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deb29c66f35141a0929327573a91ed0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8c9bc95c4ee4fe78457dec83de9d0ce","IPY_MODEL_3490fcabdbfd473f9cd4795d82bff38e","IPY_MODEL_658b56eedc3a4f3b868c105ed739ad7f"],"layout":"IPY_MODEL_09bbc5b394ea48e5b932d95eb871a47f"}},"b8c9bc95c4ee4fe78457dec83de9d0ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bacf5321e774317b39e5ac5dba3928d","placeholder":"​","style":"IPY_MODEL_a8ed3621bd3e42dd93b6f52db18bd7d5","value":"Downloading (…)/main/tokenizer.json: 100%"}},"3490fcabdbfd473f9cd4795d82bff38e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c491b5082c149e68c0a3c4f04466e61","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6ba46641bd0495192292aaa1788f896","value":466062}},"658b56eedc3a4f3b868c105ed739ad7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aee4009f42284792aa1818d63d01c7cc","placeholder":"​","style":"IPY_MODEL_fdfd80902cc344d4b3c15c5b2f1253da","value":" 466k/466k [00:00&lt;00:00, 7.95MB/s]"}},"09bbc5b394ea48e5b932d95eb871a47f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bacf5321e774317b39e5ac5dba3928d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ed3621bd3e42dd93b6f52db18bd7d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c491b5082c149e68c0a3c4f04466e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6ba46641bd0495192292aaa1788f896":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aee4009f42284792aa1818d63d01c7cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdfd80902cc344d4b3c15c5b2f1253da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc167b07edb640a9be332a8474b5dc52":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3daa4eb779f84ef4bed84d9b2d310b66","IPY_MODEL_1b799d15042344bf865374b4634466e1","IPY_MODEL_bd7ac327bb7e4ba5b45374027530c253"],"layout":"IPY_MODEL_45a193e0e1834e60b7fd4365a4c71fad"}},"3daa4eb779f84ef4bed84d9b2d310b66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d9c103f98ab47f6b058d84e9a0dc530","placeholder":"​","style":"IPY_MODEL_88eff466c6054b2b91e38059c7a14d9f","value":"Downloading (…)okenizer_config.json: 100%"}},"1b799d15042344bf865374b4634466e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4089022912854d78858c2559bf7e7943","max":1601,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e3fe4a317194dcdaa8f79f9df8a49af","value":1601}},"bd7ac327bb7e4ba5b45374027530c253":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d7bc6fe6ba4e5eb1b8eec5f133d908","placeholder":"​","style":"IPY_MODEL_3ba7f4ec5f604684a854d0fafb29c5e7","value":" 1.60k/1.60k [00:00&lt;00:00, 105kB/s]"}},"45a193e0e1834e60b7fd4365a4c71fad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d9c103f98ab47f6b058d84e9a0dc530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88eff466c6054b2b91e38059c7a14d9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4089022912854d78858c2559bf7e7943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e3fe4a317194dcdaa8f79f9df8a49af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5d7bc6fe6ba4e5eb1b8eec5f133d908":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ba7f4ec5f604684a854d0fafb29c5e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20cfeb09a8c34e5191204329979d3dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_272927580cff4509a04cec9af2021f58","IPY_MODEL_852f648e082740eb8cbe29aea839be0e","IPY_MODEL_e875a71d27bf493e995353f84cab2af9"],"layout":"IPY_MODEL_98ba872008024a51af8449b30fa410f7"}},"272927580cff4509a04cec9af2021f58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fde3adf95de3469c88f42ddc1413e0d0","placeholder":"​","style":"IPY_MODEL_08dbefdef6b04113b1c03e46d3393110","value":"Downloading (…)/main/tokenizer.json: 100%"}},"852f648e082740eb8cbe29aea839be0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d2cd216725040ec959948e83de908d3","max":1359692,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a823ad2373e4383a6836c1f083543c8","value":1359692}},"e875a71d27bf493e995353f84cab2af9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1b4e9ca4a954797b3922a71634a83d9","placeholder":"​","style":"IPY_MODEL_f7d2698d47264aeba67ceab77f9e8f2a","value":" 1.36M/1.36M [00:00&lt;00:00, 14.7MB/s]"}},"98ba872008024a51af8449b30fa410f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fde3adf95de3469c88f42ddc1413e0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08dbefdef6b04113b1c03e46d3393110":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d2cd216725040ec959948e83de908d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a823ad2373e4383a6836c1f083543c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1b4e9ca4a954797b3922a71634a83d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d2698d47264aeba67ceab77f9e8f2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6813eda08fdc4a9fb4decc2ec0b33f17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_671026bfa79c44768915cf4503714b2d","IPY_MODEL_1c98901d34784175b93a0185e439b779","IPY_MODEL_65e40755c23d45d9a633f36517e0eea2"],"layout":"IPY_MODEL_73eb29f4f36b49718724f3689cc6521c"}},"671026bfa79c44768915cf4503714b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99a8485125e24c24bf978e989951d6af","placeholder":"​","style":"IPY_MODEL_b7297e2dc10043aeb500e1e7cea77fcf","value":"Downloading (…)cial_tokens_map.json: 100%"}},"1c98901d34784175b93a0185e439b779":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_203761c8e0e74d349192b01a129373b1","max":173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_838124f6ecaa4e9e8b5e0b6555249e9c","value":173}},"65e40755c23d45d9a633f36517e0eea2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be7c54368cd94f74b53884cdc48d5070","placeholder":"​","style":"IPY_MODEL_8e3b0854c61b40dc9db1c6f16f9ffbb2","value":" 173/173 [00:00&lt;00:00, 13.0kB/s]"}},"73eb29f4f36b49718724f3689cc6521c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99a8485125e24c24bf978e989951d6af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7297e2dc10043aeb500e1e7cea77fcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"203761c8e0e74d349192b01a129373b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"838124f6ecaa4e9e8b5e0b6555249e9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be7c54368cd94f74b53884cdc48d5070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e3b0854c61b40dc9db1c6f16f9ffbb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1. libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install tokenizers transformers datasets \n!pip install wandb -qU","metadata":{"id":"zE_qPYnwb2w5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install lightning-bolts==0.7.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\nimport os\nimport pandas as pd\nfrom tokenizers import Tokenizer\nfrom transformers import PreTrainedTokenizerFast\nfrom tokenizers.processors import TemplateProcessing\nfrom transformers import AutoTokenizer\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom dataclasses import dataclass,asdict\nfrom datasets import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch import Tensor\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Transformer\nimport math\n#from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm \nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nimport yaml\nimport random, torch, numpy as np\n\nuser_secrets = UserSecretsClient()\nwandb.login(key=user_secrets.get_secret(\"wbtok\"))\n# Choose the Kaggle API token JSON file that you downloaded\n#files.upload()","metadata":{"id":"lRslFWK0b4ND","execution":{"iopub.status.busy":"2023-10-13T16:35:45.530842Z","iopub.execute_input":"2023-10-13T16:35:45.531141Z","iopub.status.idle":"2023-10-13T16:35:57.242134Z","shell.execute_reply.started":"2023-10-13T16:35:45.531117Z","shell.execute_reply":"2023-10-13T16:35:57.241216Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"2. Some stats about the data","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\nspecial_tokens = {'unk_token':\"[UNK]\",\n                  'cls_token':\"[CLS]\",\n                  'eos_token': '[EOS]',\n                  'sep_token':\"[SEP]\",\n                  'pad_token':\"[PAD]\",\n                  'mask_token':\"[MASK]\",\n                  'bos_token':\"[BOS]\"}\n# Load tokenizers\nsource_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", **special_tokens)\ntarget_tokenizer = PreTrainedTokenizerFast.from_pretrained('Sifal/EN2KAB',token='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')\n\ndef addPreprocessing(tokenizer):\n      tokenizer._tokenizer.post_processor = TemplateProcessing(\n          single=tokenizer.bos_token + \" $A \" + tokenizer.eos_token,\n          special_tokens=[(tokenizer.eos_token, tokenizer.eos_token_id), (tokenizer.bos_token, tokenizer.bos_token_id)])\n\naddPreprocessing(source_tokenizer)\naddPreprocessing(target_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T16:35:57.243767Z","iopub.execute_input":"2023-10-13T16:35:57.244370Z","iopub.status.idle":"2023-10-13T16:35:59.736691Z","shell.execute_reply.started":"2023-10-13T16:35:57.244339Z","shell.execute_reply":"2023-10-13T16:35:59.735690Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"270133d83b254b87a615f9e2cd37704c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1d561d1ff474b7e8f0848a84b644c0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e20e3267b1e4936b546e2b7ebf3980f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fd0bf5937304aa8962bb71d92eac855"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c65b0e4b47ad452aba816aa098671bef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de956bb5eb904974b4e8a2c6f68644cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19f57a1b28e445dabfa40dfa24fd0f65"}},"metadata":{}}]},{"cell_type":"code","source":"# Choose the Kaggle API token JSON file that you downloaded\n%%capture\n!mkdir ~/.kaggle\n!cp kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n!kaggle datasets download -d sifalklioui/wiki-kabyle\n!unzip wiki-kabyle.zip -d data","metadata":{"id":"wK0lh4sH-tN_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Monolingual data\npath = \"/kaggle/input/en2kab/eng2kab.tsv\"\n#files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".txt\")]\n# Kabyle English pairs\ndf = pd.read_csv(path,sep='\\t',names=['id1','en','id2','kab'], header=None).drop(columns=['id1','id2'])","metadata":{"id":"65nY8ubScYci","execution":{"iopub.status.busy":"2023-10-13T16:35:59.740994Z","iopub.execute_input":"2023-10-13T16:35:59.743295Z","iopub.status.idle":"2023-10-13T16:36:00.213001Z","shell.execute_reply.started":"2023-10-13T16:35:59.743262Z","shell.execute_reply":"2023-10-13T16:36:00.212008Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def enforce_reproducibility(use_seed=None):\n    seed = use_seed if use_seed is not None else random.randint(1, 1000000)\n    print(f\"Using seed: {seed}\")\n\n    random.seed(seed)    # python RNG\n    np.random.seed(seed) # numpy RNG\n\n    # pytorch RNGs\n    torch.manual_seed(seed)          # cpu + cuda\n    torch.cuda.manual_seed_all(seed) # multi-gpu - can be called without gpus\n    if use_seed: # slower speed! https://pytorch.org/docs/stable/notes/randomness.html#cuda-convolution-benchmarking\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark     = False\n\n    return seed","metadata":{"execution":{"iopub.status.busy":"2023-10-13T16:36:00.214877Z","iopub.execute_input":"2023-10-13T16:36:00.215407Z","iopub.status.idle":"2023-10-13T16:36:00.291358Z","shell.execute_reply.started":"2023-10-13T16:36:00.215373Z","shell.execute_reply":"2023-10-13T16:36:00.290050Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#  Let's see the distrution of the tokens in each language:","metadata":{}},{"cell_type":"code","source":"def count_tokens(text, tokenizer):\n    # Tokenize the text\n    encoding = tokenizer.tokenize(text)\n    # Return the number of tokens\n    return len(encoding)\n\nen_counts = list(df['en'].apply(lambda x: count_tokens(x, source_tokenizer)))\nkab_counts = list(df['kab'].apply(lambda x: count_tokens(x, target_tokenizer)))\n\nen_cumulative.sort()\nkab_cumulative.sort()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the filtered token count distributions\nplt.figure(figsize=(10, 6))\n\nplt.subplot(1, 2, 1)\nplt.hist(en_counts, bins=100, color='blue', alpha=0.7)\nplt.title('English Token Count Distribution')\nplt.xlabel('Number of Tokens')\nplt.ylabel('Frequency')\nplt.xlim(0, 50)\n\nplt.subplot(1, 2, 2)\nplt.hist(kab_counts, bins=100, color='green', alpha=0.7)\n\nplt.xlim(0, 50)\n\nplt.title('Kabyle Token Count Distribution ')\nplt.xlabel('Number of Tokens')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the cumulative distribution for filtered counts\nen_cumulative = np.arange(1, len(en_filtered_counts) + 1) / len(en_filtered_counts)\nkab_cumulative = np.arange(1, len(kab_filtered_counts) + 1) / len(kab_filtered_counts)\n\n# Plot the cumulative distribution graph with more x ticks\nplt.figure(figsize=(10, 6))\nplt.plot(en_filtered_counts, en_cumulative, marker='.', linestyle='none', label='English', color='blue')\nplt.plot(kab_filtered_counts, kab_cumulative, marker='.', linestyle='none', label='Kabyle', color='green')\nplt.title('Cumulative Token Count Distribution (Filtered)')\nplt.xlabel('Number of Tokens')\nplt.ylabel('Cumulative Probability')\nplt.legend()\n\n# Customize the x-axis ticks\nxticks = np.arange(0, max_threshold + 1, 1)  # Adjust the step value as needed\nyticks = np.arange(0,1.1, 0.001)  # Adjust the step value as needed\n\nplt.xticks(xticks, xticks)\nplt.yticks(yticks, yticks)\nplt.ylim(0.98, 1)\nplt.xlim(18, max_threshold)\n\nplt.grid(True)\n\nplt.show()\n\n## **It seems like we would get a lot of benefits from making a more dynamic tokenization**","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate how many tokens we're leaving for en and kab\nen_tokens_left = len(en_counts) - len(en_filtered_counts) * 0.996\nkab_tokens_left = len(kab_counts) - len(kab_filtered_counts) * 0.997\n\n# Print the number of tokens left for each language, rounded to 2 decimal places\nprint(\"Tokens left for English (en): {:.2f}\".format(en_tokens_left))\nprint(\"Tokens left for Kabyle (kab): {:.2f}\".format(kab_tokens_left))\n\n# Calculate the number of sequences relative to the average number of tokens\nen_sequences = en_tokens_left / np.mean(en_counts)\nkab_sequences = kab_tokens_left / np.mean(kab_counts)\n\nprint(\"Number of sequences lost assuming an average sequence lenght of English (en): {:.2f}\".format(en_sequences))\nprint(\"Number of sequences lost assuming an average sequence lenght of Kabyle (kab): {:.2f}\".format(kab_sequences))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## from dataclasses import dataclass\nseed_ = enforce_reproducibility()\n\n@dataclass\nclass Config:\n    seed: int = seed_\n    data_folder: str = \"/kaggle/input/en2kab/\"\n    output_dir: str = './logs'\n    src_max_length: int = 21\n    tgt_max_length: int = 22\n    add_special_tokens: bool = True\n    truncation: bool = True\n    return_tensors: str = 'pt'\n    padding: str = True\n    emb_size: int = 768\n    source_vocab_size: int = 30524  # Initialize to 0 or provide the actual value\n    target_vocab_size: int = 30000  # Initialize to 0 or provide the actual value\n    num_encoder_layers: int = 6\n    num_decoder_layers: int = 6\n    nhead: int = 4\n    ffn_hid_dim: int = 768\n    train_batch_size: int = 288\n    eval_batch_size: int = 256\n    learning_rate: float = 5e-4\n    warmup_start: float = 1e-4\n    scheduler: str = 'LinearWarmupCosineAnnealingLR'\n    num_train_epochs: int = 30\n    warmup_epochs: int = 15\n    label_smoothing : float = 0.0\n\nrun_num = 13\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-10-13T16:36:01.139272Z","iopub.execute_input":"2023-10-13T16:36:01.139725Z","iopub.status.idle":"2023-10-13T16:36:01.224213Z","shell.execute_reply.started":"2023-10-13T16:36:01.139689Z","shell.execute_reply":"2023-10-13T16:36:01.223236Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Using seed: 263843\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb.init(\n      # Set the project where this run will be logged\n      project=\"EN2KAB\", \n      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n      name=f\"VanillaTransoformer_{run_num}\", \n      # Track hyperparameters and run metadata\n      config=asdict(config))","metadata":{"id":"BRHqzzd2NnT7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class kabeng():\n    def __init__(self, part, path):\n        \n        assert part in ('train','test'), ValueError(\"Invalid value for part, please choose train or test\")\n        \n        df = pd.read_csv(\"/kaggle/input/en2kab/\"+'eng2kab.tsv',sep='\\t',names=['id1','en','id2','kab'], header=None).drop(columns=['id1','id2'])\n        if part == 'train':\n            df = df[:9*len(df)//10]\n        else:\n            df = df[9*len(df)//10:]\n        self.data = df\n        # create funtion to tokenize data\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n        data = self.data.iloc[idx]\n        return {'kab': data['kab'],\n               'en': data['en']}\n\ndef get_dataset(part, path = \"/kaggle/input/en2kab/\"):\n    return kabeng(part, path)","metadata":{"id":"YJMz1Lyi-u6g","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer_params = {\"add_special_tokens\": config.add_special_tokens,\n                \"truncation\": config.truncation,\n                \"return_tensors\": config.return_tensors,\n                \"padding\": config.padding}\n\ndef collate(batch):\n    \n    en = source_tokenizer([item['en'] for item in batch],**tokenizer_params,max_length = config.src_max_length)\n    kab = target_tokenizer([item['kab'] for item in batch],**tokenizer_params, max_length = config.tgt_max_length)\n    \n    src_max_lenght = en['attention_mask'].size(1)\n    tgt_max_lenght = kab['attention_mask'].size(1)\n\n    source_mask = torch.zeros((src_max_lenght, src_max_lenght), dtype=torch.bool)\n    target_mask = torch.tril(torch.full((tgt_max_lenght -1, tgt_max_lenght -1), float('-inf')), diagonal=-1).transpose(0, 1)\n    \n    return {\n            'source_input_ids':en['input_ids'],\n            'source_padding_mask': ~en['attention_mask'].type(torch.bool),\n            'source_mask' : source_mask,\n            'target_input_ids': kab['input_ids'],\n            'target_padding_mask': ~kab['attention_mask'][:,:-1].type(torch.bool),\n            'target_mask': target_mask\n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float,\n                 maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 src_vocab_size: int,\n                 tgt_vocab_size: int,\n                 dim_feedforward: int = 512,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = Transformer(d_model=emb_size,\n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout,\n                                       batch_first=True)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n                src_mask: Tensor,\n                tgt_mask: Tensor,\n                src_padding_mask: Tensor,\n                tgt_padding_mask: Tensor,\n                memory_key_padding_mask: Tensor):\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n        return self.generator(outs)\n\n    def encode(self, src: Tensor, src_mask: Tensor):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.src_tok_emb(src)), src_mask)\n\n    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n        return self.transformer.decoder(self.positional_encoding(\n                          self.tgt_tok_emb(tgt)), memory,\n                          tgt_mask)","metadata":{"id":"BevNVfbWAUx9","execution":{"iopub.status.busy":"2023-10-13T16:36:07.477211Z","iopub.execute_input":"2023-10-13T16:36:07.477551Z","iopub.status.idle":"2023-10-13T16:36:07.536389Z","shell.execute_reply.started":"2023-10-13T16:36:07.477524Z","shell.execute_reply":"2023-10-13T16:36:07.535339Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"transformer = Seq2SeqTransformer(config.num_encoder_layers, config.num_decoder_layers, config.emb_size,\n                                 config.nhead, config.source_vocab_size, config.target_vocab_size, config.ffn_hid_dim)\n\nfor p in transformer.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n        \nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    transformer = nn.DataParallel(transformer)\n\ntransformer.to(device)\n\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index= target_tokenizer.pad_token_id,label_smoothing = config.label_smoothing)\n\noptimizer = torch.optim.Adam(transformer.parameters(), lr=config.learning_rate, betas=(0.9, 0.98), eps=1e-9)\n\nscheduler = LinearWarmupCosineAnnealingLR(optimizer, warmup_start_lr= config.warmup_start, warmup_epochs=config.warmup_epochs, max_epochs=config.num_train_epochs)\n\n","metadata":{"id":"fg2lTvqRZHlW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize the datasets\ntrain = get_dataset('train')\ntest = get_dataset('test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train, batch_size=config.train_batch_size,collate_fn=collate)\nval_dataloader = DataLoader(test, batch_size=config.train_batch_size,collate_fn=collate)\n\ndef train_epoch(model, optimizer):\n    model.train()\n    losses = 0\n\n    for batch in tqdm(train_dataloader,desc='train'):\n        \n        source_input_ids = batch['source_input_ids'].to(device)\n        source_padding_mask = batch['source_padding_mask'].to(device)\n        source_mask = batch['source_mask'].repeat(torch.cuda.device_count(), 1).to(device)\n        \n        target_input_ids = batch['target_input_ids'].to(device)\n        target_padding_mask = batch['target_padding_mask'].to(device)\n        target_mask = batch['target_mask'].repeat(torch.cuda.device_count(), 1).to(device)\n\n        target_input_ids_ = target_input_ids[:, :-1]\n\n        logits = model(source_input_ids, target_input_ids_, source_mask, target_mask,source_padding_mask, target_padding_mask, source_padding_mask)\n\n        optimizer.zero_grad()\n        _target_input_ids = target_input_ids[:, 1:]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), _target_input_ids.reshape(-1))\n        loss.backward()\n\n        optimizer.step()\n        losses += loss.item()\n\n    return losses / len(list(train_dataloader))\n\n\ndef evaluate(model):\n    model.eval()\n    losses = 0\n\n    for batch in tqdm(val_dataloader,desc='evaluation'):\n\n        source_input_ids = batch['source_input_ids'].to(device)\n        source_padding_mask = batch['source_padding_mask'].to(device)\n        source_mask = batch['source_mask'].repeat(torch.cuda.device_count(), 1).to(device)\n        \n        target_input_ids = batch['target_input_ids'].to(device)\n        target_padding_mask = batch['target_padding_mask'].to(device)\n        target_mask = batch['target_mask'].repeat(torch.cuda.device_count(), 1).to(device)\n\n        target_input_ids_ = target_input_ids[:, :-1]\n\n        logits = model(source_input_ids, target_input_ids_, source_mask, target_mask,source_padding_mask, target_padding_mask, source_padding_mask)\n\n        optimizer.zero_grad()\n        _target_input_ids = target_input_ids[:, 1:]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), _target_input_ids.reshape(-1))\n        loss.backward()\n\n        optimizer.step()\n        losses += loss.item()\n\n    return losses / len(list(val_dataloader))","metadata":{"id":"ZVX5dG2qaZY7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint_dir = 'model_checkpoints'\nos.makedirs(model_checkpoint_dir, exist_ok=True)\n\nconfig_checkpoint_dir = 'configs'\nos.makedirs(config_checkpoint_dir, exist_ok=True)\ndef save_config(runum= None):\n    runum = run_num if run_num is None else runum\n    # Create a dictionary to store the parameters\n    model_params = {\n        \"num_encoder_layers\": config.num_encoder_layers,\n        \"num_decoder_layers\": config.num_decoder_layers,\n        \"emb_size\": config.emb_size,\n        \"nhead\": config.nhead,\n        \"source_vocab_size\": config.source_vocab_size,\n        \"target_vocab_size\": config.target_vocab_size,\n        \"ffn_hid_dim\": config.ffn_hid_dim\n    }\n\n    # Save the parameters to a YAML file (e.g., 'model_config.yaml')\n    with open(f'{config_checkpoint_dir}/model_config_run_{run_num}.yaml', 'w') as yaml_file:\n        yaml.dump(model_params, yaml_file)\n\n    \ndef load_checkpoint(run, model_checkpoint_dir='/kaggle/working/model_checkpoints',config_dir='/kaggle/working/configs', optimizer=None):\n    \n    with open(f'{config_dir}/model_config_run_{run}.yaml', 'r') as yaml_file:\n        loaded_model_params = yaml.safe_load(yaml_file)\n\n    # Create a new instance of the model with the loaded configuration\n    loaded_transformer = Seq2SeqTransformer(\n        loaded_model_params[\"num_encoder_layers\"],\n        loaded_model_params[\"num_decoder_layers\"],\n        loaded_model_params[\"emb_size\"],\n        loaded_model_params[\"nhead\"],\n        loaded_model_params[\"source_vocab_size\"],\n        loaded_model_params[\"target_vocab_size\"],\n        loaded_model_params[\"ffn_hid_dim\"]\n    )\n    \n    checkpoint = torch.load(f'{model_checkpoint_dir}/best_checkpoint_run_{run}.pt')\n    \n        # Remove the \"module.\" prefix from parameter names caused by trained with ddp\n    new_state_dict = {}\n    for key, value in checkpoint['model_state_dict'].items():\n        if key.startswith('module.'):\n            new_key = key[7:]  # Remove the \"module.\" prefix\n            new_state_dict[new_key] = value\n        else:\n            new_state_dict[key] = value\n\n    loaded_transformer.load_state_dict(new_state_dict)\n    #if optimizer:\n      #  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    loss = checkpoint['best_val_loss']\n    return loaded_transformer,epoch, loss","metadata":{"execution":{"iopub.status.busy":"2023-10-13T16:36:18.810879Z","iopub.execute_input":"2023-10-13T16:36:18.811270Z","iopub.status.idle":"2023-10-13T16:36:18.893004Z","shell.execute_reply.started":"2023-10-13T16:36:18.811240Z","shell.execute_reply":"2023-10-13T16:36:18.891012Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"save_config()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss = float('inf')  # Initialize with a large value\ncurrent_patience = 0  # Initialize patience counter\nthreshold = 0.1  # Set your desired threshold for loss improvement\ncheckpoint_patience = 8\n\ndef save_checkpoint(epoch, model, optimizer, val_loss = float('inf'), force = False,):\n    global best_val_loss, current_patience\n    if force | (val_loss < (best_val_loss - threshold)):\n        best_val_loss = val_loss\n        current_patience = 0  # Reset patience counter\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_val_loss': best_val_loss\n        }\n        model_checkpoint_path = os.path.join(model_checkpoint_dir, f'best_checkpoint_run_{run_num}.pt')\n        torch.save(checkpoint, model_checkpoint_path)\n        print(f\"Checkpoint saved at {model_checkpoint_path}\")\n    else:\n        current_patience += 1\n\n    if current_patience >= checkpoint_patience:\n        print(f\"Validation loss hasn't improved for {current_patience} epochs. Stopping training.\")\n        exit()\n    else:\n        return False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, config.num_train_epochs+1):\n    start_time = timer()\n    train_loss = train_epoch(transformer, optimizer)\n    end_time = timer()\n    val_loss = evaluate(transformer)\n    scheduler.step()\n    if epoch > config.warmup_epochs:\n        save_checkpoint(epoch, transformer, optimizer, val_loss)\n    wandb.log({\"Epoch\": epoch, \"train_loss\": train_loss,\"val_loss\":val_loss, \"lr\" : optimizer.param_groups[0]['lr']})\n    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n    \nwandb.finish()","metadata":{"id":"Km138ytlabCM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e03cc18-bb26-4e66-95b6-3aaa2d4be910","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_checkpoint(epoch,transformer.module,optimizer,force=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,_,__ = load_checkpoint(run=7)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T16:36:30.151703Z","iopub.execute_input":"2023-10-13T16:36:30.152035Z","iopub.status.idle":"2023-10-13T16:36:36.932534Z","shell.execute_reply.started":"2023-10-13T16:36:30.152007Z","shell.execute_reply":"2023-10-13T16:36:36.931641Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"token_config = {\n                \"add_special_tokens\": config.add_special_tokens,\n                \"return_tensors\": config.return_tensors,\n             }","metadata":{"id":"tW3JOl1dGJGS","execution":{"iopub.status.busy":"2023-10-13T16:36:36.934237Z","iopub.execute_input":"2023-10-13T16:36:36.934786Z","iopub.status.idle":"2023-10-13T16:36:36.984713Z","shell.execute_reply.started":"2023-10-13T16:36:36.934757Z","shell.execute_reply":"2023-10-13T16:36:36.983843Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Function to generate an output sequence using the greedy algorithm\ndef greedy_decode(model, src, src_mask, max_len, start_symbol):\n    # Move inputs to the device\n    src = src.to(device)\n    src_mask = src_mask.to(device)\n\n    # Encode the source sequence\n    memory = model.encode(src, src_mask)\n\n    # Initialize the target sequence with the start symbol\n    ys = torch.tensor([[start_symbol]]).type(torch.long).to(device)\n\n    for i in range(max_len - 1):\n        memory = memory.to(device)\n\n        # Create a target mask for autoregressive decoding\n        tgt_mask = torch.tril(torch.full((ys.size(1), ys.size(1)), float('-inf'), device=device), diagonal=-1).transpose(0, 1).to(device)\n        # Decode the target sequence\n        out = model.decode(ys, memory, tgt_mask)\n        # Generate the probability distribution over the vocabulary\n        prob = model.generator(out[:, -1])\n\n        # Select the next word with the highest probability\n        _, next_word = torch.max(prob, dim=1)\n        next_word = next_word.item()\n\n        # Append the next word to the target sequence\n        ys = torch.cat([ys,\n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n\n        # Check if the generated word is the end-of-sequence token\n        if next_word == target_tokenizer.eos_token_id:\n            break\n\n    return ys\n\n# Actual function to translate input sentence into the target language\ndef translate(model: torch.nn.Module , src_sentence: str, raw: bool = False):\n    model.to(device)\n    model.eval()\n    # Tokenize the source sentence\n    src = source_tokenizer(src_sentence, **token_config)['input_ids']\n    num_tokens = src.shape[1]\n    # Create a source mask\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n\n    # Generate the target tokens using greedy decoding\n    tgt_tokens = greedy_decode(\n        model, src, src_mask, max_len=num_tokens + 5, start_symbol=target_tokenizer.bos_token_id).flatten()\n    \n    # Decode the target tokens and clean up the result\n    if raw:\n        return tgt_tokens.tolist()\n    return target_tokenizer.decode(tgt_tokens, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:20:36.472959Z","iopub.execute_input":"2023-10-13T17:20:36.473293Z","iopub.status.idle":"2023-10-13T17:20:36.529692Z","shell.execute_reply.started":"2023-10-13T17:20:36.473266Z","shell.execute_reply":"2023-10-13T17:20:36.528730Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"type(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translate(model, \"c\")","metadata":{"execution":{"iopub.status.busy":"2023-10-13T16:40:01.640114Z","iopub.execute_input":"2023-10-13T16:40:01.640517Z","iopub.status.idle":"2023-10-13T16:40:03.580634Z","shell.execute_reply.started":"2023-10-13T16:40:01.640488Z","shell.execute_reply":"2023-10-13T16:40:03.579680Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'T ḥemmel - it sin n lqahwa'"},"metadata":{}}]},{"cell_type":"code","source":"# Greedy decoding\nresult = translate(model, \"Hello, how are you doing?\",raw=True)\ntarget_tokenizer.convert_ids_to_tokens(result,skip_special_tokens=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQIP0GRioHO1","outputId":"eaa901e9-108b-4fb3-deda-f3014c781d69","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text= 'D acu i telliḍ txeddmeḍ, neɣ ala?'\ntarget_tokenizer.tokenize(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Beam Search implementation\ndef beam_search_decode(model, src, src_mask, max_len, start_symbol, beam_size=5):\n    # Move inputs to the device\n    src = src.to(device)\n    src_mask = src_mask.to(device)\n\n\n    # Encode the source sequence\n    memory = model.encode(src, src_mask)\n\n    # Initialize the beams (sequences, score)\n    beams = [(torch.tensor([[start_symbol]]).type(torch.long).to(device), 0)]\n\n    for i in range(max_len - 1):\n        new_beams = []\n\n        for ys, score in beams:\n            # Create a target mask for autoregressive decoding\n            tgt_mask = torch.tril(torch.full((ys.size(1), ys.size(1)), float('-inf'), device=device), diagonal=-1).transpose(0, 1).to(device)\n            # Decode the target sequence\n            out = model.decode(ys, memory, tgt_mask)\n            # Generate the probability distribution over the vocabulary\n            prob = model.generator(out[:, -1])\n\n            # Get the top beam_size candidates for the next word\n            _, top_indices = torch.topk(prob, beam_size, dim=1)\n            for i,next_word in enumerate(top_indices[0]):\n                next_word = next_word.item()\n                if next_word == target_tokenizer.eos_token_id:\n                    continue\n\n                # Append the next word to the target sequence\n                new_ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n                new_score = score + prob[0][next_word].item()\n\n                # Check if the generated word is the end-of-sequence token\n                if next_word == target_tokenizer.eos_token_id:\n                    new_beams.append((new_ys, new_score))\n                else:\n                    new_beams.append((new_ys, new_score))\n\n        # Sort the beams by score and select the top beam_size beams\n        new_beams.sort(key=lambda x: x[1], reverse=True)\n        beams = new_beams[:beam_size]\n\n    # Return the best beam\n    best_beam = beams[0][0]\n    return best_beam\n\n\n# Actual function to translate input sentence into the target language using beam search\ndef translate_with_beam_search(model: torch.nn.Module, src_sentence: str, beam_size=5, raw: bool = False):\n    model.to(device)\n    model.eval()\n    # Tokenize the source sentence\n    src = source_tokenizer(src_sentence, **token_config)['input_ids']\n    num_tokens = src.shape[1]\n    # Create a source mask\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n\n    # Generate the target tokens using beam search decoding\n    tgt_tokens = beam_search_decode(\n        model, src, src_mask, max_len=num_tokens + 6, start_symbol=target_tokenizer.bos_token_id, beam_size=beam_size).flatten()\n    if raw:\n        return tgt_tokens\n    # Decode the target tokens and clean up the result\n    return target_tokenizer.decode(tgt_tokens, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n","metadata":{"id":"rsLPXUP6AiFp","execution":{"iopub.status.busy":"2023-10-13T17:16:12.789492Z","iopub.execute_input":"2023-10-13T17:16:12.789880Z","iopub.status.idle":"2023-10-13T17:16:12.845380Z","shell.execute_reply.started":"2023-10-13T17:16:12.789853Z","shell.execute_reply":"2023-10-13T17:16:12.844404Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"beams","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_tokenizer.eos_token_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(translate_with_beam_search(model, 'merci pour tout!',beam_size=100))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"om8Vk7SdAkbz","outputId":"9d3128e6-88b2-4fcc-e59c-d2cf50747305","execution":{"iopub.status.busy":"2023-10-13T17:17:35.110597Z","iopub.execute_input":"2023-10-13T17:17:35.111589Z","iopub.status.idle":"2023-10-13T17:17:59.206804Z","shell.execute_reply.started":"2023-10-13T17:17:35.111550Z","shell.execute_reply":"2023-10-13T17:17:59.205830Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"S tezmert - n kent! Ha - t - t - id\n","output_type":"stream"}]},{"cell_type":"code","source":"# It takes long to compute the BLEU Score\n\ndef bleu_score(model, src,tgt):\n    # Get the bleu score of a model\n    actual, predicted = [], []\n    for source,target in zip(src,tgt):\n        # translate encoded source text\n        translation = translate(model,source,raw=True)\n        translation = target_tokenizer.convert_ids_to_tokens(translation,skip_special_tokens=True)\n        target = target_tokenizer.tokenize(target)\n        actual.append(target)\n        predicted.append(translation)\n        \n        \n    bleu_dic = {}\n    bleu_dic['1-grams'] = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n    bleu_dic['1-2-grams'] = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n    bleu_dic['1-3-grams'] = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n    bleu_dic['1-4-grams'] = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n    \n    return bleu_dic\n","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:30:45.874899Z","iopub.execute_input":"2023-10-13T17:30:45.875580Z","iopub.status.idle":"2023-10-13T17:30:45.928042Z","shell.execute_reply.started":"2023-10-13T17:30:45.875550Z","shell.execute_reply":"2023-10-13T17:30:45.927046Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"e,k = df['en'][:71541],df['kab'][:71541],\nbleu_train = bleu_score(model, src= e, tgt=k)\nplt.bar(x = bleu_train.keys(), height = bleu_train.values())\nplt.title(\"BLEU Score with the training set\")\nplt.ylim((0,1))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bleu_test","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:21:59.121799Z","iopub.execute_input":"2023-10-13T18:21:59.122432Z","iopub.status.idle":"2023-10-13T18:21:59.173577Z","shell.execute_reply.started":"2023-10-13T18:21:59.122392Z","shell.execute_reply":"2023-10-13T18:21:59.172540Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"{'1-grams': 0.2803764184887904,\n '1-2-grams': 0.02954033248545715,\n '1-3-grams': 0.12085071590862764,\n '1-4-grams': 0.1718730126734769}"},"metadata":{}}]},{"cell_type":"code","source":"e2,k2 = df['en'][79090:],df['kab'][79090:]\nbleu_test = bleu_score(model, src= e2, tgt=k2)\nplt.bar(x = bleu_test.keys(), height = bleu_test.values())\nplt.title(\"BLEU Score with the test set\")\nplt.ylim((0,0.3))\nyticks = np.arange(0,0.3, 0.03)\nplt.yticks(yticks)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:33:01.686676Z","iopub.execute_input":"2023-10-13T17:33:01.686994Z","iopub.status.idle":"2023-10-13T17:33:01.917633Z","shell.execute_reply.started":"2023-10-13T17:33:01.686972Z","shell.execute_reply":"2023-10-13T17:33:01.916397Z"},"trusted":true},"execution_count":78,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"bleu_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}