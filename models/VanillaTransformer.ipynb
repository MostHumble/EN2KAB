{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1a130f14e7f043358916cc067cd297a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28aa98261b6947d9a97858dcff50ff4d","IPY_MODEL_7d2a2d2f64034c21b1d3c7ecc7ba06f7","IPY_MODEL_4bed7ad51aab48d1b9803923ba1aa042"],"layout":"IPY_MODEL_380394d7c571473dbe9d258612987f5d"}},"28aa98261b6947d9a97858dcff50ff4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8064793281bc4eff8d506682f2b1f80b","placeholder":"​","style":"IPY_MODEL_4dda68733df8475bbf4294976181c799","value":"Downloading (…)okenizer_config.json: 100%"}},"7d2a2d2f64034c21b1d3c7ecc7ba06f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a58a16faf4e44ee28c783217b723d871","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e69c52fe88244839ce1d70ededd401a","value":28}},"4bed7ad51aab48d1b9803923ba1aa042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db7e7b07eb4c46cea94e01574bdd5e08","placeholder":"​","style":"IPY_MODEL_81ac5e57b0ba429fa741b7b320664927","value":" 28.0/28.0 [00:00&lt;00:00, 1.40kB/s]"}},"380394d7c571473dbe9d258612987f5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8064793281bc4eff8d506682f2b1f80b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dda68733df8475bbf4294976181c799":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a58a16faf4e44ee28c783217b723d871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e69c52fe88244839ce1d70ededd401a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db7e7b07eb4c46cea94e01574bdd5e08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ac5e57b0ba429fa741b7b320664927":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32d468f9221e4514b133f493a1dc030f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b4e8c740e214363b26b0509762ff130","IPY_MODEL_17078612a6e14a93883325f96feabe55","IPY_MODEL_0629816b65b74c4f8cecf213b2e77c3b"],"layout":"IPY_MODEL_dc677cf184f547ea92f6297d949bd82a"}},"8b4e8c740e214363b26b0509762ff130":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32be718e944942fe839c3264f1e8ed38","placeholder":"​","style":"IPY_MODEL_d6f62776211f49dfa32c6842729daf7b","value":"Downloading (…)lve/main/config.json: 100%"}},"17078612a6e14a93883325f96feabe55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a779eb728cb4a6a8e989ec8c6d577f0","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1c96ea47a8c458b9f980373a0b3df98","value":570}},"0629816b65b74c4f8cecf213b2e77c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b14ea970f514a9bbb6838faf69c81ab","placeholder":"​","style":"IPY_MODEL_5e3d9bdb866b482ba1dd6636985e62de","value":" 570/570 [00:00&lt;00:00, 27.9kB/s]"}},"dc677cf184f547ea92f6297d949bd82a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32be718e944942fe839c3264f1e8ed38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f62776211f49dfa32c6842729daf7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a779eb728cb4a6a8e989ec8c6d577f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c96ea47a8c458b9f980373a0b3df98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b14ea970f514a9bbb6838faf69c81ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e3d9bdb866b482ba1dd6636985e62de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33f923d8da7b48569d1a4664cdd61df8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0c89b8f705243e980a3c9525ec420eb","IPY_MODEL_429f32080efb47d1acbf6f9fc2a1141c","IPY_MODEL_34956745f3824600968f181aca0e08d9"],"layout":"IPY_MODEL_d6ffa4759e714bc4a5aa918119a8e498"}},"e0c89b8f705243e980a3c9525ec420eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_166bc6e9565a478e8ac7dd94f660e439","placeholder":"​","style":"IPY_MODEL_e1a87ab4fdd04bcb8303acb921d38d9c","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"429f32080efb47d1acbf6f9fc2a1141c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4c433b7cb134e438dbf3f2f4d97dbcb","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac714bc71d4249509387746467cc1ba8","value":231508}},"34956745f3824600968f181aca0e08d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49cd6e4478fa4ac7bbf8855d28d4cd67","placeholder":"​","style":"IPY_MODEL_303c1610be9e469d9680de67dcd32ea2","value":" 232k/232k [00:00&lt;00:00, 3.56MB/s]"}},"d6ffa4759e714bc4a5aa918119a8e498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"166bc6e9565a478e8ac7dd94f660e439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1a87ab4fdd04bcb8303acb921d38d9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4c433b7cb134e438dbf3f2f4d97dbcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac714bc71d4249509387746467cc1ba8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49cd6e4478fa4ac7bbf8855d28d4cd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"303c1610be9e469d9680de67dcd32ea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deb29c66f35141a0929327573a91ed0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8c9bc95c4ee4fe78457dec83de9d0ce","IPY_MODEL_3490fcabdbfd473f9cd4795d82bff38e","IPY_MODEL_658b56eedc3a4f3b868c105ed739ad7f"],"layout":"IPY_MODEL_09bbc5b394ea48e5b932d95eb871a47f"}},"b8c9bc95c4ee4fe78457dec83de9d0ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bacf5321e774317b39e5ac5dba3928d","placeholder":"​","style":"IPY_MODEL_a8ed3621bd3e42dd93b6f52db18bd7d5","value":"Downloading (…)/main/tokenizer.json: 100%"}},"3490fcabdbfd473f9cd4795d82bff38e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c491b5082c149e68c0a3c4f04466e61","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6ba46641bd0495192292aaa1788f896","value":466062}},"658b56eedc3a4f3b868c105ed739ad7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aee4009f42284792aa1818d63d01c7cc","placeholder":"​","style":"IPY_MODEL_fdfd80902cc344d4b3c15c5b2f1253da","value":" 466k/466k [00:00&lt;00:00, 7.95MB/s]"}},"09bbc5b394ea48e5b932d95eb871a47f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bacf5321e774317b39e5ac5dba3928d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ed3621bd3e42dd93b6f52db18bd7d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c491b5082c149e68c0a3c4f04466e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6ba46641bd0495192292aaa1788f896":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aee4009f42284792aa1818d63d01c7cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdfd80902cc344d4b3c15c5b2f1253da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc167b07edb640a9be332a8474b5dc52":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3daa4eb779f84ef4bed84d9b2d310b66","IPY_MODEL_1b799d15042344bf865374b4634466e1","IPY_MODEL_bd7ac327bb7e4ba5b45374027530c253"],"layout":"IPY_MODEL_45a193e0e1834e60b7fd4365a4c71fad"}},"3daa4eb779f84ef4bed84d9b2d310b66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d9c103f98ab47f6b058d84e9a0dc530","placeholder":"​","style":"IPY_MODEL_88eff466c6054b2b91e38059c7a14d9f","value":"Downloading (…)okenizer_config.json: 100%"}},"1b799d15042344bf865374b4634466e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4089022912854d78858c2559bf7e7943","max":1601,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e3fe4a317194dcdaa8f79f9df8a49af","value":1601}},"bd7ac327bb7e4ba5b45374027530c253":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d7bc6fe6ba4e5eb1b8eec5f133d908","placeholder":"​","style":"IPY_MODEL_3ba7f4ec5f604684a854d0fafb29c5e7","value":" 1.60k/1.60k [00:00&lt;00:00, 105kB/s]"}},"45a193e0e1834e60b7fd4365a4c71fad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d9c103f98ab47f6b058d84e9a0dc530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88eff466c6054b2b91e38059c7a14d9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4089022912854d78858c2559bf7e7943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e3fe4a317194dcdaa8f79f9df8a49af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5d7bc6fe6ba4e5eb1b8eec5f133d908":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ba7f4ec5f604684a854d0fafb29c5e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20cfeb09a8c34e5191204329979d3dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_272927580cff4509a04cec9af2021f58","IPY_MODEL_852f648e082740eb8cbe29aea839be0e","IPY_MODEL_e875a71d27bf493e995353f84cab2af9"],"layout":"IPY_MODEL_98ba872008024a51af8449b30fa410f7"}},"272927580cff4509a04cec9af2021f58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fde3adf95de3469c88f42ddc1413e0d0","placeholder":"​","style":"IPY_MODEL_08dbefdef6b04113b1c03e46d3393110","value":"Downloading (…)/main/tokenizer.json: 100%"}},"852f648e082740eb8cbe29aea839be0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d2cd216725040ec959948e83de908d3","max":1359692,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a823ad2373e4383a6836c1f083543c8","value":1359692}},"e875a71d27bf493e995353f84cab2af9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1b4e9ca4a954797b3922a71634a83d9","placeholder":"​","style":"IPY_MODEL_f7d2698d47264aeba67ceab77f9e8f2a","value":" 1.36M/1.36M [00:00&lt;00:00, 14.7MB/s]"}},"98ba872008024a51af8449b30fa410f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fde3adf95de3469c88f42ddc1413e0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08dbefdef6b04113b1c03e46d3393110":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d2cd216725040ec959948e83de908d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a823ad2373e4383a6836c1f083543c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1b4e9ca4a954797b3922a71634a83d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d2698d47264aeba67ceab77f9e8f2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6813eda08fdc4a9fb4decc2ec0b33f17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_671026bfa79c44768915cf4503714b2d","IPY_MODEL_1c98901d34784175b93a0185e439b779","IPY_MODEL_65e40755c23d45d9a633f36517e0eea2"],"layout":"IPY_MODEL_73eb29f4f36b49718724f3689cc6521c"}},"671026bfa79c44768915cf4503714b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99a8485125e24c24bf978e989951d6af","placeholder":"​","style":"IPY_MODEL_b7297e2dc10043aeb500e1e7cea77fcf","value":"Downloading (…)cial_tokens_map.json: 100%"}},"1c98901d34784175b93a0185e439b779":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_203761c8e0e74d349192b01a129373b1","max":173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_838124f6ecaa4e9e8b5e0b6555249e9c","value":173}},"65e40755c23d45d9a633f36517e0eea2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be7c54368cd94f74b53884cdc48d5070","placeholder":"​","style":"IPY_MODEL_8e3b0854c61b40dc9db1c6f16f9ffbb2","value":" 173/173 [00:00&lt;00:00, 13.0kB/s]"}},"73eb29f4f36b49718724f3689cc6521c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99a8485125e24c24bf978e989951d6af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7297e2dc10043aeb500e1e7cea77fcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"203761c8e0e74d349192b01a129373b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"838124f6ecaa4e9e8b5e0b6555249e9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be7c54368cd94f74b53884cdc48d5070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e3b0854c61b40dc9db1c6f16f9ffbb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install tokenizers transformers datasets \n!pip install wandb -qU","metadata":{"id":"zE_qPYnwb2w5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install lightning-bolts==0.7.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\nimport os\nimport pandas as pd\nfrom tokenizers import Tokenizer\nfrom transformers import PreTrainedTokenizerFast\nfrom tokenizers.processors import TemplateProcessing\nfrom transformers import AutoTokenizer\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom dataclasses import dataclass,asdict\nfrom datasets import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch import Tensor\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Transformer\nimport math\n#from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm \nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nimport yaml\nimport random, torch, numpy as np\n\nuser_secrets = UserSecretsClient()\nwandb.login(key=user_secrets.get_secret(\"wbtok\"))\n# Choose the Kaggle API token JSON file that you downloaded\n#files.upload()","metadata":{"id":"lRslFWK0b4ND","execution":{"iopub.status.busy":"2023-10-15T09:16:19.033358Z","iopub.execute_input":"2023-10-15T09:16:19.034000Z","iopub.status.idle":"2023-10-15T09:16:19.434543Z","shell.execute_reply.started":"2023-10-15T09:16:19.033966Z","shell.execute_reply":"2023-10-15T09:16:19.433405Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msifalklioui\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nspecial_tokens = {'unk_token':\"[UNK]\",\n                  'cls_token':\"[CLS]\",\n                  'eos_token': '[EOS]',\n                  'sep_token':\"[SEP]\",\n                  'pad_token':\"[PAD]\",\n                  'mask_token':\"[MASK]\",\n                  'bos_token':\"[BOS]\"}\n\n# Load tokenizers\nsource_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", **special_tokens)\ntarget_tokenizer = PreTrainedTokenizerFast.from_pretrained('Sifal/EN2KAB',token=user_secrets.get_secret(\"hftoken\"))\nprint(source_tokenizer.eos_token)\ndef addPreprocessing(tokenizer):\n      tokenizer._tokenizer.post_processor = TemplateProcessing(\n          single=tokenizer.bos_token + \" $A \" + tokenizer.eos_token,\n          special_tokens=[(tokenizer.eos_token, tokenizer.eos_token_id), (tokenizer.bos_token, tokenizer.bos_token_id)])\n\naddPreprocessing(source_tokenizer)\naddPreprocessing(target_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:37:50.106898Z","iopub.execute_input":"2023-10-15T09:37:50.107871Z","iopub.status.idle":"2023-10-15T09:37:50.447180Z","shell.execute_reply.started":"2023-10-15T09:37:50.107826Z","shell.execute_reply":"2023-10-15T09:37:50.446373Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"[EOS]\n","output_type":"stream"}]},{"cell_type":"code","source":"source_tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:35:49.440749Z","iopub.execute_input":"2023-10-15T09:35:49.441250Z","iopub.status.idle":"2023-10-15T09:35:49.507313Z","shell.execute_reply.started":"2023-10-15T09:35:49.441208Z","shell.execute_reply":"2023-10-15T09:35:49.506147Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"30522"},"metadata":{}}]},{"cell_type":"code","source":"len(source_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:35:33.568943Z","iopub.execute_input":"2023-10-15T09:35:33.569311Z","iopub.status.idle":"2023-10-15T09:35:33.633369Z","shell.execute_reply.started":"2023-10-15T09:35:33.569283Z","shell.execute_reply":"2023-10-15T09:35:33.632170Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"30524"},"metadata":{}}]},{"cell_type":"code","source":"target_tokenizer.vocab_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Monolingual data\npath = \"/kaggle/input/en2kab/eng2kab.tsv\"\n#files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".txt\")]\n# Kabyle English pairs\ndf = pd.read_csv(path,sep='\\t',names=['id1','en','id2','kab'], header=None).drop(columns=['id1','id2'])","metadata":{"id":"65nY8ubScYci","execution":{"iopub.status.busy":"2023-10-15T09:25:34.949121Z","iopub.execute_input":"2023-10-15T09:25:34.949502Z","iopub.status.idle":"2023-10-15T09:25:35.257410Z","shell.execute_reply.started":"2023-10-15T09:25:34.949470Z","shell.execute_reply":"2023-10-15T09:25:35.256459Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def enforce_reproducibility(use_seed=None):\n    seed = use_seed if use_seed is not None else random.randint(1, 1000000)\n    print(f\"Using seed: {seed}\")\n\n    random.seed(seed)    # python RNG\n    np.random.seed(seed) # numpy RNG\n\n    # pytorch RNGs\n    torch.manual_seed(seed)          # cpu + cuda\n    torch.cuda.manual_seed_all(seed) # multi-gpu - can be called without gpus\n    if use_seed: # slower speed! https://pytorch.org/docs/stable/notes/randomness.html#cuda-convolution-benchmarking\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark     = False\n\n    return seed","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:16:30.076144Z","iopub.execute_input":"2023-10-15T09:16:30.076483Z","iopub.status.idle":"2023-10-15T09:16:30.138011Z","shell.execute_reply.started":"2023-10-15T09:16:30.076457Z","shell.execute_reply":"2023-10-15T09:16:30.136821Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"source_tokenizer.vocab_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_tokenizer.vocab_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## from dataclasses import dataclass\nseed_ = enforce_reproducibility()\n\n@dataclass\nclass Config:\n    seed: int = seed_\n    data_folder: str = \"/kaggle/input/en2kab/\"\n    output_dir: str = './logs'\n    src_max_length: int = 21\n    tgt_max_length: int = 22\n    add_special_tokens: bool = True\n    truncation: bool = True\n    return_tensors: str = 'pt'\n    padding: str = True\n    emb_size: int = 512\n    source_vocab_size: int = len(source_tokenizer) # Initialize to 0 or provide the actual value\n    target_vocab_size: int = target_tokenizer.vocab_size  # Initialize to 0 or provide the actual value\n    num_encoder_layers: int = 5\n    num_decoder_layers: int = 5\n    nhead: int = 2\n    ffn_hid_dim: int = 2048\n    train_batch_size: int = 2\n    eval_batch_size: int = 5\n    learning_rate: float = 1e-4\n    warmup_start: float = 1e-4\n    scheduler: str = ''\n    num_train_epochs: int = 1\n    warmup_epochs: int = 15\n    label_smoothing : float = 0.0\n\nrun_num = 16\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:38:49.193795Z","iopub.execute_input":"2023-10-15T09:38:49.194218Z","iopub.status.idle":"2023-10-15T09:38:49.262510Z","shell.execute_reply.started":"2023-10-15T09:38:49.194189Z","shell.execute_reply":"2023-10-15T09:38:49.261385Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Using seed: 588279\n","output_type":"stream"}]},{"cell_type":"code","source":"config.source_vocab_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(\n      # Set the project where this run will be logged\n      project=\"EN2KAB\", \n      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n      name=f\"VanillaTransoformer_{run_num}\", \n      # Track hyperparameters and run metadata\n      config=asdict(config))","metadata":{"id":"BRHqzzd2NnT7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class kabeng():\n    def __init__(self, part, path):\n        \n        assert part in ('train','test'), ValueError(\"Invalid value for part, please choose train or test\")\n        \n        df = pd.read_csv(\"/kaggle/input/en2kab/\"+'eng2kab.tsv',sep='\\t',names=['id1','en','id2','kab'], header=None).drop(columns=['id1','id2'])\n        if part == 'train':\n            df = df[:9*len(df)//10]\n        else:\n            df = df[9*len(df)//10:]\n        self.data = df\n        # create funtion to tokenize data\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n        data = self.data.iloc[idx]\n        return {'kab': data['kab'],\n               'en': data['en']}\n\ndef get_dataset(part, path = \"/kaggle/input/en2kab/\"):\n    return kabeng(part, path)","metadata":{"id":"YJMz1Lyi-u6g","execution":{"iopub.status.busy":"2023-10-15T09:16:41.777338Z","iopub.execute_input":"2023-10-15T09:16:41.777728Z","iopub.status.idle":"2023-10-15T09:16:41.841367Z","shell.execute_reply.started":"2023-10-15T09:16:41.777699Z","shell.execute_reply":"2023-10-15T09:16:41.840073Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer_params = {\"add_special_tokens\": config.add_special_tokens,\n                \"truncation\": config.truncation,\n                \"return_tensors\": config.return_tensors,\n                \"padding\": config.padding}\n\ndef collate(batch):\n    \n    en = source_tokenizer([item['en'] for item in batch],**tokenizer_params,max_length = config.src_max_length)\n    kab = target_tokenizer([item['kab'] for item in batch],**tokenizer_params, max_length = config.tgt_max_length)\n    \n    src_max_lenght = en['attention_mask'].size(1)\n    tgt_max_lenght = kab['attention_mask'].size(1)\n\n    source_mask = torch.zeros((src_max_lenght, src_max_lenght), dtype=torch.bool)\n    target_mask = torch.tril(torch.full((tgt_max_lenght -1, tgt_max_lenght -1), float('-inf')), diagonal=-1).transpose(0, 1)\n    \n    return {\n            'source_input_ids':en['input_ids'],\n            'source_padding_mask': ~en['attention_mask'].type(torch.bool),\n            'source_mask' : source_mask,\n            'target_input_ids': kab['input_ids'],\n            'target_padding_mask': ~kab['attention_mask'][:,:-1].type(torch.bool),\n            'target_mask': target_mask\n            }","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:45:38.166260Z","iopub.execute_input":"2023-10-15T09:45:38.166695Z","iopub.status.idle":"2023-10-15T09:45:38.232987Z","shell.execute_reply.started":"2023-10-15T09:45:38.166655Z","shell.execute_reply":"2023-10-15T09:45:38.231858Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"src_emb = TokenEmbedding(source_tokenizer.vocab_size+8, 512)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:34:04.912767Z","iopub.execute_input":"2023-10-15T09:34:04.915347Z","iopub.status.idle":"2023-10-15T09:34:05.131103Z","shell.execute_reply.started":"2023-10-15T09:34:04.915311Z","shell.execute_reply":"2023-10-15T09:34:05.130198Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"src_emb = self.positional_encoding(TokenEmbedding(src))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float,\n                 maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 src_vocab_size: int,\n                 tgt_vocab_size: int,\n                 dim_feedforward: int = 512,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = Transformer(d_model=emb_size,\n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout,\n                                       batch_first=True)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n                src_mask: Tensor,\n                tgt_mask: Tensor,\n                src_padding_mask: Tensor,\n                tgt_padding_mask: Tensor,\n                memory_key_padding_mask: Tensor):\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n        return self.generator(outs)\n\n    def encode(self, src: Tensor, src_mask: Tensor):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.src_tok_emb(src)), src_mask)\n\n    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n        return self.transformer.decoder(self.positional_encoding(\n                          self.tgt_tok_emb(tgt)), memory,\n                          tgt_mask)","metadata":{"id":"BevNVfbWAUx9","execution":{"iopub.status.busy":"2023-10-15T09:28:59.196338Z","iopub.execute_input":"2023-10-15T09:28:59.196774Z","iopub.status.idle":"2023-10-15T09:28:59.268304Z","shell.execute_reply.started":"2023-10-15T09:28:59.196733Z","shell.execute_reply":"2023-10-15T09:28:59.267022Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"transformer = Seq2SeqTransformer(config.num_encoder_layers, config.num_decoder_layers, config.emb_size,\n                                 config.nhead, config.source_vocab_size, config.target_vocab_size, config.ffn_hid_dim)\n\nfor p in transformer.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n        \nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    transformer = nn.DataParallel(transformer)\n\ntransformer.to(device)\n\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index= target_tokenizer.pad_token_id,label_smoothing = config.label_smoothing)\n\noptimizer = torch.optim.Adam(transformer.parameters(), lr=config.learning_rate, betas=(0.9, 0.98), eps=1e-8)\n\n#scheduler = LinearWarmupCosineAnnealingLR(optimizer, warmup_start_lr= config.warmup_start, warmup_epochs=config.warmup_epochs, max_epochs=config.num_train_epochs)\n\n","metadata":{"id":"fg2lTvqRZHlW","execution":{"iopub.status.busy":"2023-10-15T09:39:02.419816Z","iopub.execute_input":"2023-10-15T09:39:02.420210Z","iopub.status.idle":"2023-10-15T09:39:03.964840Z","shell.execute_reply.started":"2023-10-15T09:39:02.420181Z","shell.execute_reply":"2023-10-15T09:39:03.963383Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# initialize the datasets\ntrain = get_dataset('train')\ntest = get_dataset('test')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:26:16.404379Z","iopub.execute_input":"2023-10-15T09:26:16.404761Z","iopub.status.idle":"2023-10-15T09:26:16.879140Z","shell.execute_reply.started":"2023-10-15T09:26:16.404734Z","shell.execute_reply":"2023-10-15T09:26:16.877844Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train, batch_size=config.train_batch_size,collate_fn=collate,num_workers=2,shuffle=True)\nval_dataloader = DataLoader(test, batch_size=config.train_batch_size,collate_fn=collate,num_workers=2)\n\ndef train_epoch(model, optimizer):\n    model.train()\n    losses = 0\n\n    for batch in tqdm(train_dataloader,desc='train'):\n        \n        source_input_ids = batch['source_input_ids'].to(device)\n        source_padding_mask = batch['source_padding_mask'].to(device)\n        \n        target_input_ids = batch['target_input_ids'].to(device)\n        target_padding_mask = batch['target_padding_mask'].to(device)\n\n        source_mask = batch['source_mask']\n        target_mask = batch['target_mask']\n\n        if device.type != 'cpu':\n            source_mask = source_mask.repeat(torch.cuda.device_count(), 1).to(device)\n            target_mask = target_mask.repeat(torch.cuda.device_count(), 1).to(device)\n        else:\n            source_mask = source_mask.to(device)\n            target_mask = target_mask.to(device)\n            \n        target_input_ids_ = target_input_ids[:, :-1]\n\n        logits = model(source_input_ids, target_input_ids_, source_mask, target_mask,source_padding_mask, target_padding_mask, source_padding_mask)\n    \n        optimizer.zero_grad()\n        _target_input_ids = target_input_ids[:, 1:]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), _target_input_ids.reshape(-1))\n        loss.backward()\n\n        optimizer.step()\n        losses += loss.item()\n\n    return losses / len(list(train_dataloader))\n\n\ndef evaluate(model):\n    model.eval()\n    losses = 0\n\n    for batch in tqdm(val_dataloader,desc='evaluation'):\n\n        source_input_ids = batch['source_input_ids'].to(device)\n        source_padding_mask = batch['source_padding_mask'].to(device)\n        \n        source_mask = batch['source_mask']\n        target_mask = batch['target_mask']\n\n        if device.type != 'cpu':\n            source_mask = source_mask.repeat(torch.cuda.device_count(), 1).to(device)\n            target_mask = target_mask.repeat(torch.cuda.device_count(), 1).to(device)\n        else:\n            source_mask = source_mask.to(device)\n            target_mask = target_mask.to(device)\n\n        target_input_ids = batch['target_input_ids'].to(device)\n        target_padding_mask = batch['target_padding_mask'].to(device)\n\n        target_input_ids_ = target_input_ids[:, :-1]\n        \n        logits = model(source_input_ids, target_input_ids_, source_mask, target_mask,source_padding_mask, target_padding_mask, source_padding_mask)\n\n        optimizer.zero_grad()\n        _target_input_ids = target_input_ids[:, 1:]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), _target_input_ids.reshape(-1))\n        loss.backward()\n\n        optimizer.step()\n        losses += loss.item()\n\n    return losses / len(list(val_dataloader))","metadata":{"id":"ZVX5dG2qaZY7","execution":{"iopub.status.busy":"2023-10-15T09:51:58.871518Z","iopub.execute_input":"2023-10-15T09:51:58.871916Z","iopub.status.idle":"2023-10-15T09:51:58.946491Z","shell.execute_reply.started":"2023-10-15T09:51:58.871888Z","shell.execute_reply":"2023-10-15T09:51:58.945313Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model_checkpoint_dir = 'model_checkpoints'\nos.makedirs(model_checkpoint_dir, exist_ok=True)\n\nconfig_checkpoint_dir = 'configs'\nos.makedirs(config_checkpoint_dir, exist_ok=True)\ndef save_config(runum= None):\n    runum = run_num if run_num is None else runum\n    # Create a dictionary to store the parameters\n    model_params = {\n        \"num_encoder_layers\": config.num_encoder_layers,\n        \"num_decoder_layers\": config.num_decoder_layers,\n        \"emb_size\": config.emb_size,\n        \"nhead\": config.nhead,\n        \"source_vocab_size\": config.source_vocab_size,\n        \"target_vocab_size\": config.target_vocab_size,\n        \"ffn_hid_dim\": config.ffn_hid_dim\n    }\n\n    # Save the parameters to a YAML file (e.g., 'model_config.yaml')\n    with open(f'{config_checkpoint_dir}/model_config_run_{run_num}.yaml', 'w') as yaml_file:\n        yaml.dump(model_params, yaml_file)\n\n    \ndef load_checkpoint(run, model_checkpoint_dir='/kaggle/working/model_checkpoints',config_dir='/kaggle/working/configs', optimizer=None):\n    \n    with open(f'{config_dir}/model_config_run_{run}.yaml', 'r') as yaml_file:\n        loaded_model_params = yaml.safe_load(yaml_file)\n\n    # Create a new instance of the model with the loaded configuration\n    loaded_transformer = Seq2SeqTransformer(\n        loaded_model_params[\"num_encoder_layers\"],\n        loaded_model_params[\"num_decoder_layers\"],\n        loaded_model_params[\"emb_size\"],\n        loaded_model_params[\"nhead\"],\n        loaded_model_params[\"source_vocab_size\"],\n        loaded_model_params[\"target_vocab_size\"],\n        loaded_model_params[\"ffn_hid_dim\"]\n    )\n    \n    checkpoint = torch.load(f'{model_checkpoint_dir}/best_checkpoint_run_{run}.pt')\n    \n        # Remove the \"module.\" prefix from parameter names caused by trained with ddp\n    new_state_dict = {}\n    for key, value in checkpoint['model_state_dict'].items():\n        if key.startswith('module.'):\n            new_key = key[7:]  # Remove the \"module.\" prefix\n            new_state_dict[new_key] = value\n        else:\n            new_state_dict[key] = value\n\n    loaded_transformer.load_state_dict(new_state_dict)\n    #if optimizer:\n      #  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    loss = checkpoint['best_val_loss']\n    return loaded_transformer,epoch, loss","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:29:11.012416Z","iopub.execute_input":"2023-10-15T09:29:11.012844Z","iopub.status.idle":"2023-10-15T09:29:11.079180Z","shell.execute_reply.started":"2023-10-15T09:29:11.012811Z","shell.execute_reply":"2023-10-15T09:29:11.078085Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"save_config()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss = float('inf')  # Initialize with a large value\ncurrent_patience = 0  # Initialize patience counter\nthreshold = 0.01  # Set your desired threshold for loss improvement\ncheckpoint_patience = 8\n\ndef save_checkpoint(epoch, model, optimizer, val_loss = float('inf'), force = False,):\n    global best_val_loss, current_patience\n    if force | (val_loss < (best_val_loss - threshold)):\n        best_val_loss = val_loss\n        current_patience = 0  # Reset patience counter\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_val_loss': best_val_loss\n        }\n        model_checkpoint_path = os.path.join(model_checkpoint_dir, f'best_checkpoint_run_{run_num}.pt')\n        torch.save(checkpoint, model_checkpoint_path)\n        print(f\"Checkpoint saved at {model_checkpoint_path}\")\n    else:\n        current_patience += 1\n\n    if current_patience >= checkpoint_patience:\n        current_patience\n        print(f\"Validation loss hasn't improved for {current_patience} epochs. Stopping training.\")\n        exit()\n    else:\n        return False","metadata":{"execution":{"iopub.status.busy":"2023-10-15T09:17:04.431328Z","iopub.execute_input":"2023-10-15T09:17:04.431688Z","iopub.status.idle":"2023-10-15T09:17:04.492415Z","shell.execute_reply.started":"2023-10-15T09:17:04.431656Z","shell.execute_reply":"2023-10-15T09:17:04.491149Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, config.num_train_epochs+1):\n    start_time = timer()\n    train_loss = train_epoch(transformer, optimizer)\n    end_time = timer()\n    val_loss = evaluate(transformer)\n    #scheduler.step()\n    if epoch > config.warmup_epochs:\n        save_checkpoint(epoch, transformer, optimizer, val_loss)\n    wandb.log({\"Epoch\": epoch, \"train_loss\": train_loss,\"val_loss\":val_loss, \"lr\" : optimizer.param_groups[0]['lr']})\n    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))","metadata":{"id":"Km138ytlabCM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e03cc18-bb26-4e66-95b6-3aaa2d4be910","execution":{"iopub.status.busy":"2023-10-15T09:52:05.077797Z","iopub.execute_input":"2023-10-15T09:52:05.078292Z","iopub.status.idle":"2023-10-15T09:52:12.878408Z","shell.execute_reply.started":"2023-10-15T09:52:05.078249Z","shell.execute_reply":"2023-10-15T09:52:12.876102Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"train:   0%|          | 0/35771 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([12, 12])\ntorch.Size([11, 11])\ntorch.Size([9, 9])\ntorch.Size([8, 8])\ntorch.Size([6, 6])\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 1/35771 [00:03<30:45:56,  3.10s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([12, 12])\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 2/35771 [00:03<17:49:32,  1.79s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([14, 14])\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 3/35771 [00:04<13:10:09,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([10, 10])\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 4/35771 [00:05<10:56:55,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([14, 14])\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 5/35771 [00:06<9:34:10,  1.04it/s] ","output_type":"stream"},{"name":"stdout","text":"torch.Size([7, 7])\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 6/35771 [00:06<8:50:37,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([7, 7])\n","output_type":"stream"},{"name":"stderr","text":"train:   0%|          | 6/35771 [00:07<12:21:48,  1.24s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[63], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39mnum_train_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m----> 3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      5\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(transformer)\n","Cell \u001b[0;32mIn[62], line 35\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), _target_input_ids\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     33\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 35\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(train_dataloader))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"!rm /kaggle/working/model_checkpoints/best_checkpoint.pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_checkpoint(epoch,transformer.module,optimizer,force=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token_config = {\n                \"add_special_tokens\": config.add_special_tokens,\n                \"return_tensors\": config.return_tensors,\n             }","metadata":{"id":"tW3JOl1dGJGS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate an output sequence using the greedy algorithm\ndef greedy_decode(model, src, src_mask, max_len, start_symbol):\n    # Move inputs to the device\n    src = src.to(device)\n    src_mask = src_mask.to(device)\n\n    # Encode the source sequence\n    memory = model.encode(src, src_mask)\n\n    # Initialize the target sequence with the start symbol\n    ys = torch.tensor([[start_symbol]]).type(torch.long).to(device)\n\n    for i in range(max_len - 1):\n        memory = memory.to(device)\n\n        # Create a target mask for autoregressive decoding\n        tgt_mask = torch.tril(torch.full((ys.size(1), ys.size(1)), float('-inf'), device=device), diagonal=-1).transpose(0, 1).to(device)\n        # Decode the target sequence\n        out = model.decode(ys, memory, tgt_mask)\n        # Generate the probability distribution over the vocabulary\n        prob = model.generator(out[:, -1])\n\n        # Select the next word with the highest probability\n        _, next_word = torch.max(prob, dim=1)\n        next_word = next_word.item()\n\n        # Append the next word to the target sequence\n        ys = torch.cat([ys,\n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n\n        # Check if the generated word is the end-of-sequence token\n        if next_word == target_tokenizer.eos_token_id:\n            break\n\n    return ys\n\n# Actual function to translate input sentence into the target language\ndef translate(model: torch.nn.Module , src_sentence: str, raw: bool = False):\n    model.to(device)\n    model.eval()\n    # Tokenize the source sentence\n    src = source_tokenizer(src_sentence, **token_config)['input_ids']\n    num_tokens = src.shape[1]\n    # Create a source mask\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n\n    # Generate the target tokens using greedy decoding\n    tgt_tokens = greedy_decode(\n        model, src, src_mask, max_len=num_tokens + 5, start_symbol=target_tokenizer.bos_token_id).flatten()\n    \n    # Decode the target tokens and clean up the result\n    if raw:\n        return tgt_tokens.tolist()\n    return target_tokenizer.decode(tgt_tokens, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Beam Search implementation\ndef beam_search_decode(model, src, src_mask, max_len, start_symbol, beam_size=5):\n    # Move inputs to the device\n    src = src.to(device)\n    src_mask = src_mask.to(device)\n\n\n    # Encode the source sequence\n    memory = model.encode(src, src_mask)\n\n    # Initialize the beams (sequences, score)\n    beams = [(torch.tensor([[start_symbol]]).type(torch.long).to(device), 0)]\n\n    for i in range(max_len - 1):\n        new_beams = []\n\n        for ys, score in beams:\n            # Create a target mask for autoregressive decoding\n            tgt_mask = torch.tril(torch.full((ys.size(1), ys.size(1)), float('-inf'), device=device), diagonal=-1).transpose(0, 1).to(device)\n            # Decode the target sequence\n            out = model.decode(ys, memory, tgt_mask)\n            # Generate the probability distribution over the vocabulary\n            prob = model.generator(out[:, -1])\n\n            # Get the top beam_size candidates for the next word\n            _, top_indices = torch.topk(prob, beam_size, dim=1)\n            for i,next_word in enumerate(top_indices[0]):\n                next_word = next_word.item()\n                if next_word == target_tokenizer.eos_token_id:\n                    continue\n\n                # Append the next word to the target sequence\n                new_ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n                new_score = score + prob[0][next_word].item()\n\n                # Check if the generated word is the end-of-sequence token\n                if next_word == target_tokenizer.eos_token_id:\n                    new_beams.append((new_ys, new_score))\n                else:\n                    new_beams.append((new_ys, new_score))\n\n        # Sort the beams by score and select the top beam_size beams\n        new_beams.sort(key=lambda x: x[1], reverse=True)\n        beams = new_beams[:beam_size]\n\n    # Return the best beam\n    best_beam = beams[0][0]\n    return best_beam\n\n\n# Actual function to translate input sentence into the target language using beam search\ndef translate_with_beam_search(model: torch.nn.Module, src_sentence: str, beam_size=5, raw: bool = False):\n    model.to(device)\n    model.eval()\n    # Tokenize the source sentence\n    src = source_tokenizer(src_sentence, **token_config)['input_ids']\n    num_tokens = src.shape[1]\n    # Create a source mask\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n\n    # Generate the target tokens using beam search decoding\n    tgt_tokens = beam_search_decode(\n        model, src, src_mask, max_len=num_tokens + 6, start_symbol=target_tokenizer.bos_token_id, beam_size=beam_size).flatten()\n    if raw:\n        return tgt_tokens\n    # Decode the target tokens and clean up the result\n    return target_tokenizer.decode(tgt_tokens, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n","metadata":{"id":"rsLPXUP6AiFp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,_,__ = load_checkpoint(run=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"story = '''One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt. Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\" Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'''.split('.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for s in story:\n    print('sentence: ',s,'\\ntranlsation: ', translate_with_beam_search(model,s,beam_size=4))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"om8Vk7SdAkbz","outputId":"9d3128e6-88b2-4fcc-e59c-d2cf50747305","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It takes long to compute the BLEU Score\n\ndef bleu_score(model, src,tgt):\n    # Get the bleu score of a model\n    actual, predicted = [], []\n    for source,target in zip(src,tgt):\n        # translate encoded source text\n        translation = translate(model,source,raw=True)\n        translation = target_tokenizer.convert_ids_to_tokens(translation,skip_special_tokens=True)\n        target = target_tokenizer.tokenize(target)\n        actual.append(target)\n        predicted.append(translation)\n        \n    bleu = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n    \n    return bleu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e,k = df['en'][:71541],df['kab'][:71541],\nbleu_train = bleu_score(model, src= e, tgt=k)\nplt.bar(x = bleu_train.keys(), height = bleu_train.values())\nplt.title(\"BLEU Score with the training set\")\nplt.ylim((0,1))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e2,k2 = df['en'][71541:],df['kab'][71541:]\nbleu_test = bleu_score(model, src= e2, tgt=k2)\nplt.bar(x = bleu_test.keys(), height = bleu_test.values())\nplt.title(\"BLEU Score with the test set\")\nplt.ylim((0,0.3))\nyticks = np.arange(0,0.3, 0.03)\nplt.yticks(yticks)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bleu_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}